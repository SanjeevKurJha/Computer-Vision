{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from facerec_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "import pyttsx3\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recog_model = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", face_recog_model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "   \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onStart(): \n",
    "    print('starting') \n",
    "\n",
    "def onWord(name, location, length): \n",
    "    print('word', name, location, length) \n",
    "\n",
    "def onEnd(name, completed): \n",
    "    print('finishing', name, completed)\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 528.14307\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading the pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recog_model.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nfrom PIL import Image\\nim = Image.open(\"/images/ashish.jpg\")\\npixelMap = im.load()\\n\\nimg = Image.new( im.mode, im.size)\\npixelsNew = im.load()\\nfor i in range(img.size[0]):\\n    for j in range(img.size[1]):\\n        if 205 in pixelMap[i,j]:\\n           pixelMap[i,j] = (0,96,96)\\n        pixelsNew[i,j] = pixelMap[i,j]\\nim.close()\\nimg.show()       \\nimg.save(\"images/ashish.jpg\") \\nimg.close()\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "from PIL import Image\n",
    "im = Image.open(\"/images/ashish.jpg\")\n",
    "pixelMap = im.load()\n",
    "\n",
    "img = Image.new( im.mode, im.size)\n",
    "pixelsNew = im.load()\n",
    "for i in range(img.size[0]):\n",
    "    for j in range(img.size[1]):\n",
    "        if 205 in pixelMap[i,j]:\n",
    "           pixelMap[i,j] = (0,96,96)\n",
    "        pixelsNew[i,j] = pixelMap[i,j]\n",
    "im.close()\n",
    "img.show()       \n",
    "img.save(\"images/ashish.jpg\") \n",
    "img.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"sanjeev\"] = img_to_encoding(\"images/sanjeev.jpg\", face_recog_model)\n",
    "database[\"aishwarya rai\"] = img_to_encoding(\"images/aishwarya rai.jpg\", face_recog_model)\n",
    "database[\"a r rahman\"] = img_to_encoding(\"images/a r rahman.jpg\", face_recog_model)\n",
    "database[\"ashish\"] = img_to_encoding(\"images/ashish.jpg\", face_recog_model)\n",
    "database[\"vijay\"] = img_to_encoding(\"images/vijay.jpg\", face_recog_model)\n",
    "database[\"madhu\"] = img_to_encoding(\"images/madhu.jpg\", face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    if dist < 0.95:\n",
    "        print(\"It's \" + str(identity) + \", welcome home!\")\n",
    "        engine.connect('started-utterance', onStart) \n",
    "        engine.connect('started-word', onWord) \n",
    "        engine.connect('finished-utterance', onEnd) \n",
    "        sen = \"Welcome back home\"+ str(identity);\n",
    "        engine.say(sen)\n",
    "        engine.runAndWait() \n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        engine.connect('started-utterance', onStart) \n",
    "        engine.connect('started-word', onWord) \n",
    "        engine.connect('finished-utterance', onEnd)\n",
    "        sen = \"It's not\" + str(identity) +  \", you are not allow\";\n",
    "        engine.say(sen)\n",
    "        engine.runAndWait()\n",
    "        door_open = False\n",
    "        \n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's madhu, welcome home!\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 13 9\n",
      "word None 13 9\n",
      "word None 13 9\n",
      "word None 13 9\n",
      "word None 13 9\n",
      "word None 13 9\n",
      "word None 13 9\n",
      "word None 13 9\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9016429, True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/ex_madhu.jpg\", \"madhu\", database, face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's sanjeev, welcome home!\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4599099, True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/ex_sanjeev.jpg\", \"sanjeev\", database, face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's ashish, welcome home!\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1828834, True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/ex_ashish.jpg\", \"ashish\", database, face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog(image_path, database, model):\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    min_dist = 100\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        dist = np.linalg.norm(encoding - db_enc)\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name.\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    if min_dist > 0.95:\n",
    "        print(\"Not in the database.\")\n",
    "        engine.connect('started-utterance', onStart) \n",
    "        engine.connect('started-word', onWord) \n",
    "        engine.connect('finished-utterance', onEnd) \n",
    "        sen = \"Not in the database.\";\n",
    "        engine.say(sen)\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        engine.connect('started-utterance', onStart) \n",
    "        engine.connect('started-word', onWord) \n",
    "        engine.connect('finished-utterance', onEnd) \n",
    "        sen = \"Welcome back home\"+ str(identity);\n",
    "        engine.say(sen)\n",
    "        engine.runAndWait()\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's aishwarya rai, the distance is 0.6103996\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 13 13\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "word None 27 3\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6103996, 'aishwarya rai')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recog(\"images/ex_ar.jpg\", database, face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's ashish, the distance is 0.1828834\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "word None 13 10\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1828834, 'ashish')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recog(\"images/ex_ashish.jpg\", database, face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's sanjeev, the distance is 0.4599099\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 0 7\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 8 4\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "word None 13 11\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n",
      "finishing None True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4599099, 'sanjeev')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recog(\"images/ex_sanjeev.jpg\", database, face_recog_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "IaknP",
   "launcher_item_id": "5UMr4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
