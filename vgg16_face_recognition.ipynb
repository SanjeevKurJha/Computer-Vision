{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7CICNH1BuHL"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2570
    },
    "colab_type": "code",
    "id": "El3fIgem55Ws",
    "outputId": "f2294767-64c0-47b6-fa60-e8c4aff86643"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 17s 0us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 102)               417894    \n",
      "=================================================================\n",
      "Total params: 134,678,438\n",
      "Trainable params: 417,894\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n",
      "Found 34605 images belonging to 102 classes.\n",
      "Found 2856 images belonging to 102 classes.\n",
      "Epoch 1/500\n",
      "1081/1081 [==============================] - 13155s 12s/step - loss: 4.4396 - acc: 0.1211 - val_loss: 5.2995 - val_acc: 0.1046\n",
      "Epoch 2/500\n",
      "1081/1081 [==============================] - 623s 576ms/step - loss: 3.9551 - acc: 0.1739 - val_loss: 4.2606 - val_acc: 0.2458\n",
      "Epoch 3/500\n",
      "1081/1081 [==============================] - 619s 572ms/step - loss: 3.7459 - acc: 0.2024 - val_loss: 4.4928 - val_acc: 0.2309\n",
      "Epoch 4/500\n",
      "1081/1081 [==============================] - 617s 571ms/step - loss: 3.6227 - acc: 0.2187 - val_loss: 4.5731 - val_acc: 0.2627\n",
      "Epoch 5/500\n",
      "1081/1081 [==============================] - 615s 569ms/step - loss: 3.5355 - acc: 0.2362 - val_loss: 4.2412 - val_acc: 0.2567\n",
      "Epoch 6/500\n",
      "1081/1081 [==============================] - 616s 570ms/step - loss: 3.4670 - acc: 0.2427 - val_loss: 4.2868 - val_acc: 0.2288\n",
      "Epoch 7/500\n",
      "1081/1081 [==============================] - 617s 571ms/step - loss: 3.4157 - acc: 0.2513 - val_loss: 4.3930 - val_acc: 0.2507\n",
      "Epoch 8/500\n",
      "1081/1081 [==============================] - 617s 571ms/step - loss: 3.3798 - acc: 0.2604 - val_loss: 4.3130 - val_acc: 0.2829\n",
      "Epoch 9/500\n",
      "1081/1081 [==============================] - 614s 568ms/step - loss: 3.3486 - acc: 0.2654 - val_loss: 4.4641 - val_acc: 0.3067\n",
      "Epoch 10/500\n",
      "1081/1081 [==============================] - 618s 571ms/step - loss: 3.3148 - acc: 0.2737 - val_loss: 4.4561 - val_acc: 0.2758\n",
      "Epoch 11/500\n",
      "1081/1081 [==============================] - 614s 568ms/step - loss: 3.2956 - acc: 0.2816 - val_loss: 4.4534 - val_acc: 0.2900\n",
      "Epoch 12/500\n",
      "1081/1081 [==============================] - 617s 571ms/step - loss: 3.2617 - acc: 0.2804 - val_loss: 4.4949 - val_acc: 0.3021\n",
      "Epoch 13/500\n",
      "1081/1081 [==============================] - 616s 570ms/step - loss: 3.2218 - acc: 0.2910 - val_loss: 4.4588 - val_acc: 0.3407\n",
      "Epoch 14/500\n",
      "1081/1081 [==============================] - 616s 570ms/step - loss: 3.1974 - acc: 0.2915 - val_loss: 4.2932 - val_acc: 0.3176\n",
      "Epoch 15/500\n",
      "1081/1081 [==============================] - 616s 570ms/step - loss: 3.1588 - acc: 0.2987 - val_loss: 4.1321 - val_acc: 0.3555\n",
      "Epoch 16/500\n",
      "1081/1081 [==============================] - 617s 571ms/step - loss: 3.1530 - acc: 0.3049 - val_loss: 4.3098 - val_acc: 0.3442\n",
      "Epoch 17/500\n",
      "1081/1081 [==============================] - 616s 570ms/step - loss: 3.1559 - acc: 0.3024 - val_loss: 4.1125 - val_acc: 0.3573\n",
      "Epoch 18/500\n",
      "1081/1081 [==============================] - 624s 577ms/step - loss: 3.1148 - acc: 0.3094 - val_loss: 4.1512 - val_acc: 0.3757\n",
      "Epoch 19/500\n",
      "1081/1081 [==============================] - 618s 572ms/step - loss: 3.1010 - acc: 0.3109 - val_loss: 4.3724 - val_acc: 0.3605\n",
      "Epoch 20/500\n",
      "1081/1081 [==============================] - 619s 572ms/step - loss: 3.0951 - acc: 0.3110 - val_loss: 4.1728 - val_acc: 0.3895\n",
      "Epoch 21/500\n",
      "1081/1081 [==============================] - 618s 571ms/step - loss: 3.0194 - acc: 0.3209 - val_loss: 4.2980 - val_acc: 0.3385\n",
      "Epoch 22/500\n",
      "1081/1081 [==============================] - 629s 582ms/step - loss: 3.0632 - acc: 0.3197 - val_loss: 4.4678 - val_acc: 0.3913\n",
      "Epoch 23/500\n",
      "1081/1081 [==============================] - 618s 572ms/step - loss: 3.0589 - acc: 0.3214 - val_loss: 4.3702 - val_acc: 0.3789\n",
      "Epoch 24/500\n",
      "1081/1081 [==============================] - 618s 572ms/step - loss: 3.0388 - acc: 0.3216 - val_loss: 4.3815 - val_acc: 0.3265\n",
      "Epoch 25/500\n",
      "1081/1081 [==============================] - 619s 573ms/step - loss: 3.0196 - acc: 0.3262 - val_loss: 4.4516 - val_acc: 0.3842\n",
      "Epoch 26/500\n",
      "1081/1081 [==============================] - 617s 571ms/step - loss: 3.0241 - acc: 0.3265 - val_loss: 3.9704 - val_acc: 0.4033\n",
      "Epoch 27/500\n",
      "1081/1081 [==============================] - 617s 571ms/step - loss: 2.9709 - acc: 0.3288 - val_loss: 4.1956 - val_acc: 0.3778\n",
      "Epoch 28/500\n",
      "1081/1081 [==============================] - 618s 572ms/step - loss: 2.9410 - acc: 0.3307 - val_loss: 3.8923 - val_acc: 0.4030\n",
      "Epoch 29/500\n",
      "1081/1081 [==============================] - 619s 573ms/step - loss: 2.9688 - acc: 0.3308 - val_loss: 3.8846 - val_acc: 0.4040\n",
      "Epoch 30/500\n",
      "1081/1081 [==============================] - 619s 573ms/step - loss: 2.9316 - acc: 0.3307 - val_loss: 3.9573 - val_acc: 0.3619\n",
      "Epoch 31/500\n",
      "1081/1081 [==============================] - 620s 573ms/step - loss: 2.9196 - acc: 0.3355 - val_loss: 4.0375 - val_acc: 0.3775\n",
      "Epoch 32/500\n",
      "1081/1081 [==============================] - 632s 584ms/step - loss: 2.9340 - acc: 0.3360 - val_loss: 4.1540 - val_acc: 0.3778\n",
      "Epoch 33/500\n",
      "1081/1081 [==============================] - 622s 575ms/step - loss: 2.9192 - acc: 0.3377 - val_loss: 3.9449 - val_acc: 0.3764\n",
      "Epoch 34/500\n",
      "1081/1081 [==============================] - 610s 564ms/step - loss: 2.8994 - acc: 0.3408 - val_loss: 4.0083 - val_acc: 0.3506\n",
      "Epoch 35/500\n",
      "1081/1081 [==============================] - 612s 566ms/step - loss: 2.8922 - acc: 0.3394 - val_loss: 3.9902 - val_acc: 0.3651\n",
      "Epoch 36/500\n",
      "1081/1081 [==============================] - 601s 556ms/step - loss: 2.8822 - acc: 0.3428 - val_loss: 3.9842 - val_acc: 0.4132\n",
      "Epoch 37/500\n",
      "1081/1081 [==============================] - 593s 548ms/step - loss: 2.8599 - acc: 0.3478 - val_loss: 4.1182 - val_acc: 0.3970\n",
      "Epoch 38/500\n",
      "1081/1081 [==============================] - 592s 548ms/step - loss: 2.8534 - acc: 0.3513 - val_loss: 4.0892 - val_acc: 0.3771\n",
      "Epoch 39/500\n",
      "1081/1081 [==============================] - 590s 546ms/step - loss: 2.8684 - acc: 0.3487 - val_loss: 3.7734 - val_acc: 0.4465\n",
      "Epoch 40/500\n",
      "1081/1081 [==============================] - 597s 552ms/step - loss: 2.8683 - acc: 0.3496 - val_loss: 4.0086 - val_acc: 0.3927\n",
      "Epoch 41/500\n",
      "1081/1081 [==============================] - 603s 558ms/step - loss: 2.8384 - acc: 0.3547 - val_loss: 4.2674 - val_acc: 0.3860\n",
      "Epoch 42/500\n",
      "1081/1081 [==============================] - 603s 558ms/step - loss: 2.8219 - acc: 0.3536 - val_loss: 3.7988 - val_acc: 0.3977\n",
      "Epoch 43/500\n",
      "1081/1081 [==============================] - 604s 559ms/step - loss: 2.8312 - acc: 0.3521 - val_loss: 3.9051 - val_acc: 0.4196\n",
      "Epoch 44/500\n",
      "1081/1081 [==============================] - 607s 561ms/step - loss: 2.8278 - acc: 0.3532 - val_loss: 4.0639 - val_acc: 0.3562\n",
      "Epoch 45/500\n",
      "1081/1081 [==============================] - 611s 566ms/step - loss: 2.8060 - acc: 0.3595 - val_loss: 4.1140 - val_acc: 0.3534\n",
      "Epoch 46/500\n",
      "1081/1081 [==============================] - 614s 568ms/step - loss: 2.8178 - acc: 0.3576 - val_loss: 3.7632 - val_acc: 0.4182\n",
      "Epoch 47/500\n",
      "1081/1081 [==============================] - 608s 562ms/step - loss: 2.8031 - acc: 0.3603 - val_loss: 3.8623 - val_acc: 0.4178\n",
      "Epoch 48/500\n",
      " 408/1081 [==========>...................] - ETA: 5:57 - loss: 2.7978 - acc: 0.3608"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jan 11 14:18:06 2019\n",
    "\n",
    "@author: Sanjeev Jha\n",
    "\"\"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import SGD, Adam,RMSprop\n",
    "import cv2, numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering(\"th\")\n",
    "\"\"\"\n",
    "ISSUE: Keras MaxPooling2D gives ValueError: Negative dimension size caused by subtracting 2 from 1 for 'MaxPool_x'\n",
    "url:https://github.com/keras-team/keras/issues/3945\n",
    "solution: model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")) \n",
    "\"\"\"\n",
    "\"\"\"\n",
    "alpha. Also referred to as the learning rate or step size. The proportion that weights are updated (e.g. 0.001). \n",
    "Larger values (e.g. 0.3) results in faster initial learning before the rate is updated. Smaller values (e.g. 1.0E-5) \n",
    "slow learning right down during training\n",
    "beta1. The exponential decay rate for the first moment estimates (e.g. 0.9).\n",
    "beta2. The exponential decay rate for the second-moment estimates (e.g. 0.999). \n",
    "This value should be set close to 1.0 on problems with a sparse gradient (e.g. NLP and computer vision problems).\n",
    "epsilon. Is a very small number to prevent any division by zero in the implementation (e.g. 10E-8).\n",
    "Further, learning rate decay can also be used with Adam. The paper uses a decay rate alpha = alpha/sqrt(t) updted each epoch (t) for the logistic regression demonstration.\n",
    "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "The Adam paper suggests:\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "TensorFlow: learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08.\n",
    "Keras: lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models.\n",
    "Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm \n",
    "that can handle sparse gradients on noisy problems.\n",
    "Adam is relatively easy to configure where the default configuration parameters do well on most problems.\n",
    "\"\"\"\n",
    "num_classes=102\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    net = VGG16(weights='imagenet') \n",
    "    net.layers.pop()\n",
    "    model=Sequential()\n",
    "    #net.trainable = False\n",
    "    for l in net.layers:\n",
    "      model.add(l)\n",
    "      l.trainable = False\n",
    "     \n",
    "    for m in model.layers:\n",
    "       m.trainable=False\n",
    " \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()   \n",
    "    adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=True)\n",
    "    model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "   \n",
    "    #data augementation\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                       rotation_range = 30,\n",
    "                                       width_shift_range = 0.2,\n",
    "                                       height_shift_range = 0.2,\n",
    "                                       shear_range = 0.2,\n",
    "                                       zoom_range = 0.2,\n",
    "                                       horizontal_flip = True)\n",
    " \n",
    "    \n",
    "                                       \n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "   \n",
    "    train_generator = train_datagen.flow_from_directory('/content/drive/My Drive/Model_data/train_data',\n",
    "                                                            target_size=(224,224),\n",
    "                                                            color_mode='rgb',\n",
    "                                                            batch_size=32,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            interpolation='nearest',\n",
    "                                                            shuffle=True)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory('/content/drive/My Drive/Model_data/test_data',\n",
    "                                                          target_size=(224,224),\n",
    "                                                          color_mode='rgb',\n",
    "                                                          batch_size=32,\n",
    "                                                          class_mode='categorical',\n",
    "                                                          interpolation='nearest',\n",
    "                                                          shuffle=True)\n",
    "\n",
    "    steps_per_epoch=train_generator.n\n",
    "    batch_size_train=train_generator.batch_size\n",
    "    step_size_train=int(steps_per_epoch/batch_size_train)\n",
    "    validation_steps=test_generator.n\n",
    "    batch_size_test=test_generator.batch_size\n",
    "    step_size_test=int(validation_steps/batch_size_test)\n",
    "\n",
    "    \n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=step_size_train,epochs=500,validation_data=test_generator,validation_steps=step_size_test, verbose=1)\n",
    "    model.save(\"Image_Classifier_VGG16_102_50_E500.h5\")\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.legend(['training', 'validation'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "     \n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.legend(['training','validation'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vgg16_face recognition_50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
